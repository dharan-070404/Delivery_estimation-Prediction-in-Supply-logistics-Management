{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Days for shipping (real)  Days for shipment (scheduled)  \\\n",
      "count             180519.000000                  180519.000000   \n",
      "mean                   3.497654                       2.931847   \n",
      "std                    1.623722                       1.374449   \n",
      "min                    0.000000                       0.000000   \n",
      "25%                    2.000000                       2.000000   \n",
      "50%                    3.000000                       4.000000   \n",
      "75%                    5.000000                       4.000000   \n",
      "max                    6.000000                       4.000000   \n",
      "\n",
      "       Benefit per order  Sales per customer  Late_delivery_risk  \\\n",
      "count      180519.000000       180519.000000       180519.000000   \n",
      "mean           21.974989          183.107609            0.548291   \n",
      "std           104.433526          120.043670            0.497664   \n",
      "min         -4274.979980            7.490000            0.000000   \n",
      "25%             7.000000          104.379997            0.000000   \n",
      "50%            31.520000          163.990005            1.000000   \n",
      "75%            64.800003          247.399994            1.000000   \n",
      "max           911.799988         1939.989990            1.000000   \n",
      "\n",
      "         Category Id    Customer Id  Customer Zipcode  Department Id  \\\n",
      "count  180519.000000  180519.000000     180516.000000  180519.000000   \n",
      "mean       31.851451    6691.379495      35921.126914       5.443460   \n",
      "std        15.640064    4162.918106      37542.461122       1.629246   \n",
      "min         2.000000       1.000000        603.000000       2.000000   \n",
      "25%        18.000000    3258.500000        725.000000       4.000000   \n",
      "50%        29.000000    6457.000000      19380.000000       5.000000   \n",
      "75%        45.000000    9779.000000      78207.000000       7.000000   \n",
      "max        76.000000   20757.000000      99205.000000      12.000000   \n",
      "\n",
      "            Latitude  ...  Order Item Quantity          Sales  \\\n",
      "count  180519.000000  ...        180519.000000  180519.000000   \n",
      "mean       29.719955  ...             2.127638     203.772096   \n",
      "std         9.813646  ...             1.453451     132.273077   \n",
      "min       -33.937553  ...             1.000000       9.990000   \n",
      "25%        18.265432  ...             1.000000     119.980003   \n",
      "50%        33.144863  ...             1.000000     199.919998   \n",
      "75%        39.279617  ...             3.000000     299.950012   \n",
      "max        48.781933  ...             5.000000    1999.989990   \n",
      "\n",
      "       Order Item Total  Order Profit Per Order  Order Zipcode  \\\n",
      "count     180519.000000           180519.000000   24840.000000   \n",
      "mean         183.107609               21.974989   55426.132327   \n",
      "std          120.043670              104.433526   31919.279101   \n",
      "min            7.490000            -4274.979980    1040.000000   \n",
      "25%          104.379997                7.000000   23464.000000   \n",
      "50%          163.990005               31.520000   59405.000000   \n",
      "75%          247.399994               64.800003   90008.000000   \n",
      "max         1939.989990              911.799988   99301.000000   \n",
      "\n",
      "       Product Card Id  Product Category Id  Product Description  \\\n",
      "count    180519.000000        180519.000000                  0.0   \n",
      "mean        692.509764            31.851451                  NaN   \n",
      "std         336.446807            15.640064                  NaN   \n",
      "min          19.000000             2.000000                  NaN   \n",
      "25%         403.000000            18.000000                  NaN   \n",
      "50%         627.000000            29.000000                  NaN   \n",
      "75%        1004.000000            45.000000                  NaN   \n",
      "max        1363.000000            76.000000                  NaN   \n",
      "\n",
      "       Product Price  Product Status  \n",
      "count  180519.000000        180519.0  \n",
      "mean      141.232550             0.0  \n",
      "std       139.732492             0.0  \n",
      "min         9.990000             0.0  \n",
      "25%        50.000000             0.0  \n",
      "50%        59.990002             0.0  \n",
      "75%       199.990005             0.0  \n",
      "max      1999.989990             0.0  \n",
      "\n",
      "[8 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "filename = 'dataset_4.csv'\n",
    "\n",
    "# Read the data into a Pandas DataFrame\n",
    "data = pd.read_csv(filename, encoding='latin-1')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days for shipping (real)</th>\n",
       "      <th>Days for shipment (scheduled)</th>\n",
       "      <th>Benefit per order</th>\n",
       "      <th>Sales per customer</th>\n",
       "      <th>Delivery Status</th>\n",
       "      <th>Late_delivery_risk</th>\n",
       "      <th>Category Id</th>\n",
       "      <th>Category Name</th>\n",
       "      <th>Customer City</th>\n",
       "      <th>Customer Country</th>\n",
       "      <th>...</th>\n",
       "      <th>Order Item Total</th>\n",
       "      <th>Order Region</th>\n",
       "      <th>Order State</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Product Card Id</th>\n",
       "      <th>Product Category Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Price</th>\n",
       "      <th>shipping date (DateOrders)</th>\n",
       "      <th>Shipping Mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>314.640015</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>...</td>\n",
       "      <td>314.640015</td>\n",
       "      <td>Southeast Asia</td>\n",
       "      <td>Java Occidental</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>02-03-2018 22:56</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-249.089996</td>\n",
       "      <td>311.359985</td>\n",
       "      <td>Late delivery</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>...</td>\n",
       "      <td>311.359985</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Rajastán</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>1/18/2018 12:27</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-247.779999</td>\n",
       "      <td>309.720001</td>\n",
       "      <td>Shipping on time</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>EE. UU.</td>\n",
       "      <td>...</td>\n",
       "      <td>309.720001</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Rajastán</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>1/17/2018 12:06</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22.860001</td>\n",
       "      <td>304.809998</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>EE. UU.</td>\n",
       "      <td>...</td>\n",
       "      <td>304.809998</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>1/16/2018 11:45</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>298.250000</td>\n",
       "      <td>Advance shipping</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>Sporting Goods</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>...</td>\n",
       "      <td>298.250000</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>PENDING_PAYMENT</td>\n",
       "      <td>1360</td>\n",
       "      <td>73</td>\n",
       "      <td>Smart watch</td>\n",
       "      <td>327.75</td>\n",
       "      <td>1/15/2018 11:24</td>\n",
       "      <td>Standard Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Days for shipping (real)  Days for shipment (scheduled)  Benefit per order  \\\n",
       "0                         3                              4          91.250000   \n",
       "1                         5                              4        -249.089996   \n",
       "2                         4                              4        -247.779999   \n",
       "3                         3                              4          22.860001   \n",
       "4                         2                              4         134.210007   \n",
       "\n",
       "   Sales per customer   Delivery Status  Late_delivery_risk  Category Id  \\\n",
       "0          314.640015  Advance shipping                   0           73   \n",
       "1          311.359985     Late delivery                   1           73   \n",
       "2          309.720001  Shipping on time                   0           73   \n",
       "3          304.809998  Advance shipping                   0           73   \n",
       "4          298.250000  Advance shipping                   0           73   \n",
       "\n",
       "    Category Name Customer City Customer Country  ...  Order Item Total  \\\n",
       "0  Sporting Goods        Caguas      Puerto Rico  ...        314.640015   \n",
       "1  Sporting Goods        Caguas      Puerto Rico  ...        311.359985   \n",
       "2  Sporting Goods      San Jose          EE. UU.  ...        309.720001   \n",
       "3  Sporting Goods   Los Angeles          EE. UU.  ...        304.809998   \n",
       "4  Sporting Goods        Caguas      Puerto Rico  ...        298.250000   \n",
       "\n",
       "     Order Region      Order State     Order Status  Product Card Id  \\\n",
       "0  Southeast Asia  Java Occidental         COMPLETE             1360   \n",
       "1      South Asia         Rajastán          PENDING             1360   \n",
       "2      South Asia         Rajastán           CLOSED             1360   \n",
       "3         Oceania       Queensland         COMPLETE             1360   \n",
       "4         Oceania       Queensland  PENDING_PAYMENT             1360   \n",
       "\n",
       "   Product Category Id  Product Name Product Price shipping date (DateOrders)  \\\n",
       "0                   73  Smart watch         327.75           02-03-2018 22:56   \n",
       "1                   73  Smart watch         327.75            1/18/2018 12:27   \n",
       "2                   73  Smart watch         327.75            1/17/2018 12:06   \n",
       "3                   73  Smart watch         327.75            1/16/2018 11:45   \n",
       "4                   73  Smart watch         327.75            1/15/2018 11:24   \n",
       "\n",
       "    Shipping Mode  \n",
       "0  Standard Class  \n",
       "1  Standard Class  \n",
       "2  Standard Class  \n",
       "3  Standard Class  \n",
       "4  Standard Class  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the unwanted feature columns in the data which is not related to the prediction we are doing\n",
    "columns_to_remove = ['Type','Customer Email', 'Customer Fname', 'Customer Lname', 'Customer Password',\n",
    "                     'Customer Segment', 'Customer State', 'Customer Street', 'Order Item Discount',\n",
    "                     'Order Item Discount Rate', 'Order Item Profit Ratio', 'Order Profit Per Order',\n",
    "                     'Order Zipcode', 'Product Description', 'Product Image', 'Product Status']\n",
    "\n",
    "# Remove the specified columns\n",
    "data_updated = data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "filename_updated = 'dataset_4_updated.csv'\n",
    "data_updated.to_csv(filename_updated, index=False)\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "data_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the date and time format in coloumn order date (dateorders)\n",
    "filename_updated = 'dataset_4_updated.csv'\n",
    "data1 = pd.read_csv(filename_updated)\n",
    "\n",
    "# Define a function to standardize the date format\n",
    "def standardize_date_format(date_str):\n",
    "    # Split the date string into date and time components\n",
    "    date_parts = date_str.split()\n",
    "    date = date_parts[0]\n",
    "    time = date_parts[1] if len(date_parts) > 1 else ''\n",
    "    \n",
    "    # Split the date into day, month, and year components\n",
    "    parts = date.split('-') if '-' in date else date.split('/')\n",
    "    day = parts[1] if len(parts[1]) == 2 else '0' + parts[1]\n",
    "    month = parts[0] if len(parts[0]) == 2 else '0' + parts[0]\n",
    "    year = parts[2]\n",
    "    \n",
    "    # Reformat the date string\n",
    "    standardized_date = f\"{year}-{month}-{day} {time}\"\n",
    "    \n",
    "    return standardized_date\n",
    "\n",
    "# Apply the function to standardize the date format\n",
    "data1['order date (DateOrders)'] = data1['order date (DateOrders)'].apply(standardize_date_format)\n",
    "data1['shipping date (DateOrders)']=data1['shipping date (DateOrders)'].apply(standardize_date_format)\n",
    "# Save the updated dataset to a new CSV file\n",
    "data1.to_csv(filename_updated, index=False)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after standardizing the order datetime and shipping datetime \n",
    "#now we are making them into two sperate columns like for date and time seperately\n",
    "filename_updated = 'dataset_4_updated.csv'\n",
    "data2 = pd.read_csv(filename_updated)\n",
    "data2['order date (DateOrders)'] = pd.to_datetime(data2['order date (DateOrders)'], format=\"%Y-%m-%d %H:%M\")\n",
    "# Extract date component into a new column 'order_date'\n",
    "data2['order_date'] = data2['order date (DateOrders)'].dt.date\n",
    "# Extract time component into a new column 'order_time'\n",
    "data2['order_time'] = data2['order date (DateOrders)'].dt.time\n",
    "# Convert 'shipping date (DateOrders)' column to datetime format with specified format\n",
    "data2['shipping date (DateOrders)'] = pd.to_datetime(data2['shipping date (DateOrders)'], format=\"%Y-%m-%d %H:%M\")\n",
    "# Extract date component into a new column 'shipping_date'\n",
    "data2['shipping_date'] = data2['shipping date (DateOrders)'].dt.date\n",
    "# Extract time component into a new column 'shipping_time'\n",
    "data2['shipping_time'] = data2['shipping date (DateOrders)'].dt.time\n",
    "# Drop the original 'order date (DateOrders)' and 'shipping date (DateOrders)' columns\n",
    "data2.drop(columns=['order date (DateOrders)', 'shipping date (DateOrders)'], inplace=True)\n",
    "data2.to_csv(filename_updated,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv('dataset_4_updated.csv')\n",
    "\n",
    "# Convert 'order_date' and 'shipping_date' columns to datetime format with the appropriate format string\n",
    "data3['order_date'] = pd.to_datetime(data3['order_date'], format='%Y-%m-%d')\n",
    "data3['shipping_date'] = pd.to_datetime(data3['shipping_date'], format='%Y-%m-%d')\n",
    "\n",
    "# Calculate procured date by subtracting 'order_date' from 'shipping_date'\n",
    "data3['procured_days'] = (data3['shipping_date'] - data3['order_date']).dt.days\n",
    "\n",
    "# Save the updated dataset to the same CSV file\n",
    "data3.to_csv('dataset_4_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset_4_updated.csv')\n",
    "columns_to_drop = ['Benefit per order', 'Sales per customer', 'Category Id', 'Category Name', 'Customer Id', 'Department Id', 'Department Name', 'Order Customer Id', 'Order Id', 'Order Item Cardprod Id', 'Order Item Id', 'Order Item Product Price', 'Order Item Quantity', 'Sales', 'Order Item Total', 'Product Card Id', 'Product Category Id']\n",
    "existing_columns = [col for col in columns_to_drop if col in data.columns]\n",
    "data.drop(columns=existing_columns, inplace=True)\n",
    "data.to_csv('dataset_4_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are calculating few features from the existing features which can be helpful in predicting the delivery time\n",
    "#adding a new feature \"processing_time\" which is basically duration between the order date and shipping date it gives as how many days it took for processing\n",
    "data=pd.read_csv('dataset_4_updated.csv')\n",
    "data['order_date'] = pd.to_datetime(data['order_date'])\n",
    "data['shipping_date'] = pd.to_datetime(data['shipping_date'])\n",
    "data['processing_time']=(data['shipping_date']-data['order_date']).dt.days\n",
    "data.to_csv('dataset_4_updated.csv',index=False)\n",
    "\n",
    "\n",
    "#now lets add another feature which is 'shipment_status' which provides the status of shipement whether is it early, delayed or ontime\n",
    "# Define a threshold for early and delayed shipments in terms of days\n",
    "early_threshold_days = 0\n",
    "delayed_threshold_days = 3\n",
    "\n",
    "# Categorize shipment status based on processing time\n",
    "data['shipment_status'] = 'On time'  # Default to 'On time'\n",
    "data.loc[data['processing_time'] < early_threshold_days, 'shipment_status'] = 'Early'\n",
    "data.loc[data['processing_time'] > delayed_threshold_days, 'shipment_status'] = 'Delayed'\n",
    "data.to_csv('dataset_4_updated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv('dataset_4_updated.csv')\n",
    "# Filter out the rows where the \"Order Country\" is \"India\"\n",
    "filtered_data = data[data['Order Country'] == 'India']\n",
    "# Save the filtered data to a new CSV file named \"final_data.csv\"\n",
    "filtered_data.to_csv('final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bikaner' 'Sangli' 'Jabalpur' 'Delhi' 'Hubli' 'Bangalore' 'Mirzapur'\n",
      " 'Raipur' 'Kanpur' 'Ulhasnagar' 'Ajmer' 'Vadodara' 'Bhilai' 'Ujjain'\n",
      " 'Pune' 'Rajkot' 'Gorakhpur' 'Nagpur' 'Jaipur' 'Aurangabad' 'Hyderabad'\n",
      " 'Vijayawada' 'Thane' 'Mumbai' 'Durgapur' 'Bhavnagar' 'Mangalore' 'Ranchi'\n",
      " 'Durg' 'Belgaum' 'Solapur' 'Bihar Sharif' 'Patna' 'Faridabad' 'Madurai'\n",
      " 'Fatehpur' 'Ichalkaranji' 'Kota' 'Guwahati' 'Gwalior' 'Visakhapatnam'\n",
      " 'Kollam' 'Nellore' 'Chennai' 'Bokaro' 'Malegaon' 'Thiruvananthapuram'\n",
      " 'Agra' 'Rohtak' 'Moradabad' 'Nagercoil' 'Kulti' 'Imphal' 'Surat'\n",
      " 'Bhatpara' 'Parbhani' 'Bhubaneswar' 'Bhatinda' 'Srinagar' 'Varanasi'\n",
      " 'Dewas' 'Amritsar' 'Kakinada' 'Korba' 'Bijapur' 'Kukatpalli' 'Warangal'\n",
      " 'Tiruchchirappalli' 'Lucknow' 'Darbhanga' 'Meerut' 'Ludhiana' 'Firozabad'\n",
      " 'Kozhikode' 'Kalyan' 'Kochi' 'Mysore' 'Kolhapur' 'Pimpri' 'Ganganagar'\n",
      " 'Panihati' 'Tiruppur' 'Saharanpur' 'Bellary' 'Jodhpur' 'Jamnagar' 'Dhule'\n",
      " 'Aligarh' 'Mathura' 'Amravati' 'Chandigarh' 'Bareilly' 'Allahabad'\n",
      " 'Nasik' 'Karnal' 'Hapur' 'Jammu' 'Bhopal' 'Bhiwandi' 'Ambattur' 'Guntur'\n",
      " 'Coimbatore' 'Indore' 'Salem' 'Patiala' 'Puducherry' 'Cuttack' 'Barasat'\n",
      " 'Tirupati' 'Naihati' 'Akola' 'Etawah' 'Tirunelveli' 'Asansol' 'Udaipur'\n",
      " 'Jhansi' 'Muzaffarpur' 'Panipat' 'Gaya' 'Sonipat' 'Avadi' 'Baranagar'\n",
      " 'Jamshedpur' 'Brahmapur' 'Thanjavur' 'Bilaspur' 'Ratlam' 'Dehra Dun'\n",
      " 'Kamarhati' 'Karimnagar' 'Satna' 'Nizamabad' 'Gulbarga' 'Shahjahanpur'\n",
      " 'Barddhaman' 'Hisar' 'Tumkur' 'Jalna' 'Anantapur' 'Mau' 'Bhilwara'\n",
      " 'Bharatpur' 'Ghaziabad' 'Latur' 'New Delhi' 'Shimoga']\n",
      "Number of unique order cities: 146\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_data.csv')\n",
    "# Get unique order cities\n",
    "unique_order_cities = data['Order City'].unique()\n",
    "# Display unique order cities in an array\n",
    "print(unique_order_cities)\n",
    "# Get the length of the array\n",
    "num_unique_order_cities = len(unique_order_cities)\n",
    "print(\"Number of unique order cities:\", num_unique_order_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Days for shipping (real)  Days for shipment (scheduled)  \\\n",
      "0                            5                              4   \n",
      "1                            4                              4   \n",
      "2                            2                              1   \n",
      "3                            2                              1   \n",
      "4                            2                              1   \n",
      "...                        ...                            ...   \n",
      "5840                         2                              4   \n",
      "5841                         4                              4   \n",
      "5842                         2                              4   \n",
      "5843                         2                              4   \n",
      "5844                         4                              4   \n",
      "\n",
      "        Delivery Status  Late_delivery_risk Customer City Customer Country  \\\n",
      "0         Late delivery                   1        Caguas      Puerto Rico   \n",
      "1      Shipping on time                   0      San Jose          EE. UU.   \n",
      "2         Late delivery                   1        Caguas      Puerto Rico   \n",
      "3         Late delivery                   1       Peabody          EE. UU.   \n",
      "4         Late delivery                   1        Caguas      Puerto Rico   \n",
      "...                 ...                 ...           ...              ...   \n",
      "5840   Advance shipping                   0        Caguas      Puerto Rico   \n",
      "5841  Shipping canceled                   0        Madera          EE. UU.   \n",
      "5842   Advance shipping                   0       Orlando          EE. UU.   \n",
      "5843   Advance shipping                   0       Orlando          EE. UU.   \n",
      "5844   Shipping on time                   0        Caguas      Puerto Rico   \n",
      "\n",
      "      Customer Zipcode   Latitude   Longitude        Market  ...  \\\n",
      "0                725.0  18.279451  -66.037064  Pacific Asia  ...   \n",
      "1              95125.0  37.292233 -121.881279  Pacific Asia  ...   \n",
      "2                725.0  18.278439  -66.037056  Pacific Asia  ...   \n",
      "3               1960.0  42.526276  -70.927032  Pacific Asia  ...   \n",
      "4                725.0  18.284050  -66.037056  Pacific Asia  ...   \n",
      "...                ...        ...         ...           ...  ...   \n",
      "5840             725.0  18.267492  -66.370567  Pacific Asia  ...   \n",
      "5841           93638.0  36.970711 -120.058853  Pacific Asia  ...   \n",
      "5842           32822.0  28.516270  -81.305832  Pacific Asia  ...   \n",
      "5843           32822.0  28.516270  -81.305832  Pacific Asia  ...   \n",
      "5844             725.0  18.290380  -66.370613  Pacific Asia  ...   \n",
      "\n",
      "     Product Price   Shipping Mode  order_date order_time shipping_date  \\\n",
      "0       327.750000  Standard Class  2018-01-13   12:27:00    2018-01-18   \n",
      "1       327.750000  Standard Class  2018-01-13   12:06:00    2018-01-17   \n",
      "2       327.750000     First Class  2018-01-13   08:15:00    2018-01-15   \n",
      "3       327.750000     First Class  2018-01-13   07:54:00    2018-01-15   \n",
      "4       327.750000     First Class  2018-01-13   07:33:00    2018-01-15   \n",
      "...            ...             ...         ...        ...           ...   \n",
      "5840    399.980011  Standard Class  2016-01-17   10:30:00    2016-01-19   \n",
      "5841    399.980011  Standard Class  2016-01-17   05:56:00    2016-01-21   \n",
      "5842    399.980011  Standard Class  2016-01-16   23:59:00    2016-01-18   \n",
      "5843    399.980011  Standard Class  2016-01-16   23:59:00    2016-01-18   \n",
      "5844    399.980011  Standard Class  2016-01-15   18:54:00    2016-01-19   \n",
      "\n",
      "     shipping_time  processing_time shipment_status order city latitude  \\\n",
      "0         12:27:00                5         Delayed             28.0181   \n",
      "1         12:06:00                4         Delayed             28.0181   \n",
      "2         08:15:00                2         On time             16.8530   \n",
      "3         07:54:00                2         On time             16.8530   \n",
      "4         07:33:00                2         On time             16.8530   \n",
      "...            ...              ...             ...                 ...   \n",
      "5840      10:30:00                2         On time             23.3600   \n",
      "5841      05:56:00                4         Delayed             23.3340   \n",
      "5842      23:59:00                2         On time             13.6500   \n",
      "5843      23:59:00                2         On time             13.6500   \n",
      "5844      18:54:00                4         Delayed              8.1750   \n",
      "\n",
      "     order city longitude  \n",
      "0                 73.3169  \n",
      "1                 73.3169  \n",
      "2                 74.5830  \n",
      "3                 74.5830  \n",
      "4                 74.5830  \n",
      "...                   ...  \n",
      "5840              85.3300  \n",
      "5841              75.0370  \n",
      "5842              79.4200  \n",
      "5843              79.4200  \n",
      "5844              77.4306  \n",
      "\n",
      "[5453 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the datasets\n",
    "supply_chain_data = pd.read_csv('final_data.csv')\n",
    "cities_data = pd.read_csv('worldcities.csv')\n",
    "# Filter cities_data to include only Indian cities\n",
    "indian_cities = cities_data[cities_data['country'] == 'India']\n",
    "# Merge supply_chain_data with indian_cities based on 'city'/'order city' column\n",
    "merged_data = pd.merge(supply_chain_data, indian_cities[['city_ascii', 'lat', 'lng']], left_on='Order City', right_on='city_ascii', how='left')\n",
    "merged_data = merged_data.dropna(subset=['lat', 'lng'])\n",
    "# Drop the 'city' column (optional)\n",
    "merged_data.drop('city_ascii', axis=1, inplace=True)\n",
    "# Rename latitude and longitude columns\n",
    "merged_data.rename(columns={'lat': 'order city latitude', 'lng': 'order city longitude'}, inplace=True)\n",
    "# Print or further process merged_data\n",
    "print(merged_data)\n",
    "merged_data.to_csv('final_data2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "final_data = pd.read_csv('final_data2.csv')\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = 6371 * c  # Radius of the Earth in kilometers\n",
    "    return distance\n",
    "\n",
    "# Apply the haversine function to each row using .apply()\n",
    "final_data['distance'] = final_data.apply(lambda row: haversine(row['Latitude'], row['Longitude'], row['order city latitude'], row['order city longitude']), axis=1)\n",
    "\n",
    "final_data.to_csv('final_data2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standard Class' 'First Class' 'Same Day' 'Second Class']\n"
     ]
    }
   ],
   "source": [
    "final_data = pd.read_csv('final_data2.csv')\n",
    "\n",
    "# Get unique shipping modes\n",
    "unique_shipping_modes = final_data['Shipping Mode'].unique()\n",
    "\n",
    "# Display unique shipping modes\n",
    "print(unique_shipping_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of shipping modes to multipliers\n",
    "shipping_mode_multipliers = {\n",
    "    'Same Day': 0,\n",
    "    'First Class': 0.5,\n",
    "    'Second Class': 0.8,\n",
    "    'Standard Class': 1\n",
    "}\n",
    "# Add the 'multiplier' column based on the 'Shipping Mode' column\n",
    "final_data['multiplier'] = final_data['Shipping Mode'].map(shipping_mode_multipliers)\n",
    "final_data.to_csv('final_data2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'approx_time' column by multiplying 'multiplier' with 'distance'\n",
    "final_data['approx_time'] = (final_data['multiplier'] * final_data['distance']).round(4)\n",
    "final_data.to_csv('final_data2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('final_data2.csv')\n",
    "# Define the columns to normalize\n",
    "columns_to_normalize = ['approx_time']\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(1, 4))\n",
    "# Normalize the selected columns\n",
    "df['transit_time'] = scaler.fit_transform(df[columns_to_normalize])\n",
    "# Round the normalized values to 4 decimal places\n",
    "df['transit_time'] = df['transit_time'].round()\n",
    "df['transit_time']=np.ceil(df['transit_time'])\n",
    "df['transit_time'] = df['transit_time'].astype(int)\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('final_data2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we got processingtime and transit time we can add them to get effective_delivery_time\n",
    "df = pd.read_csv('final_data2.csv')\n",
    "# Add transit_time and processing_time to calculate effective_delivery_time\n",
    "df['effective_delivery_time'] = df['transit_time'] + df['processing_time']\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('final_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
